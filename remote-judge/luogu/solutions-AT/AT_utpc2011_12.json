[
    {
        "content": "\u642c\u8fd0+\u7ffb\u8bd1\u4e00\u6ce2\u9898\u89e3\uff0c[\u6e90\u5730\u5740](https://kimiyuki.net/writeup/algo/etc/utpc2011-l/)\n\n#### \u601d\u8def\uff1a\u5c0f\u6ce2\u6811+\u91cd\u94fe\u5256\u5206+\u4e8c\u5206\u67e5\u627e+\u5750\u6807\u538b\u7f29\n\n\u5982\u679c\u5e8f\u5217\u662f\u56fa\u5b9a\u7684\u800c\u4e0d\u662f\u6811\uff0c\u5e76\u4e14\u5728\u95f4\u9694\u4e2d\u6709\u8bb8\u591a\u5173\u4e8e $L_{th}$ \u7684\u67e5\u8be2\uff0c\u5219\u53ef\u4ee5\u4f7f\u7528 $Wavlet$ \u6811\u4f7f\u7528 $O(\\log N)$ \u8fdb\u884c\u5904\u7406\u3002\n\n\u6211\u4eec\u9700\u8981\u4e00\u79cd\u5c06\u6811\u4e0a\u7684\u67e5\u8be2\u653e\u5165\u5217\u4e2d\u7684\u67e5\u8be2\u7684\u7b97\u6cd5\uff0c\u4e8e\u662f\u6211\u4eec\u4e0a\u91cd\u94fe\u5256\u5206\u3002\n\n\u4f46\u662f\u8fd9\u6837\u4e0d\u80fd\u5f88\u597d\u5730\u7ec4\u5408\u4ece\u4e0d\u540c\u7684 $Wavlet$ \u6811\u83b7\u5f97\u7684\u201c\u95f4\u9694\u4e2d\u7684 $Kth$ \u6570\u201d\u3002\n\n\u56e0\u6b64\uff0c $Wavlet$ \u6811\u7684\u53e6\u4e00\u51fd\u6570\u7528\u4e8e\u8ba1\u7b97\u201c\u95f4\u9694\u4e2d\u5c0f\u4e8ex\u7684\u6570\u91cf\u201d\uff0c\u5e76\u5c06\u5b83\u4eec\u76f8\u52a0\u7684\u7ed3\u679c\u4e0e $L$ \u8fdb\u884c\u6bd4\u8f83\u3002\u4e8c\u5206\u67e5\u627e\u3002\n\n\u4f46\u662f\u8fd9\u6837\u4f1aT\u3002\n\n $Wavlet$ \u6811\u548c\u4e8c\u5206\u7b54\u6848\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u8981\u4e58\u4ee5 $O(\\log M)$ (\u5c31\u662f\u53ef\u5904\u7406\u7684\u6700\u5927\u503cM\uff09\uff0c\u4f46\u662f\u5982\u679c\u4e8b\u5148\u4f7f\u7528\u5750\u6807\u538b\u7f29\u5c06\u5176\u4e22\u5f03\u4ee5\u4f7f $M\u2264N$ \uff0c\u5219\u5c31\u8dd1\u5f97\u5feb\u4e00\u70b9\u3002\n \n$ O(n \\log n)$ \u7528\u4e8e\u9884\u5904\u7406\u3002\u603b\u590d\u6742\u5ea6 $O(N \\log N+Q(\\log N)^3) $\n\n```cpp\n#include <bits/stdc++.h>\n#define REP(i, n) for (int i = 0; (i) < int(n); ++ (i))\n#define REP_R(i, n) for (int i = int(n) - 1; (i) >= 0; -- (i))\n#define ALL(x) begin(x), end(x)\nusing ll = long long;\nusing namespace std;\ntemplate <class T> inline void chmax(T & a, T const & b) { a = max(a, b); }\n\ntemplate <typename T>\nmap<T, int> coordinate_compression_map(vector<T> const & xs) {\n    int n = xs.size();\n    vector<int> ys(n);\n    iota(ALL(ys), 0);\n    sort(ALL(ys), [&](int i, int j) { return xs[i] < xs[j]; });\n    map<T,int> f;\n    for (int i : ys) {\n        if (not f.count(xs[i])) { // make unique\n            int j = f.size();\n            f[xs[i]] = j; // f[xs[i]] has a side effect, increasing the f.size()\n        }\n    }\n    return f;\n}\n\ntemplate <typename T>\nvector<int> apply_compression(map<T, int> const & f, vector<T> const & xs) {\n    int n = xs.size();\n    vector<int> ys(n);\n    REP (i, n) ys[i] = f.at(xs[i]);\n    return ys;\n}\n\nstruct heavy_light_decomposition {\n    vector<vector<int> > path; // : V' -> list of V, bottom to top order\n    vector<int> path_of; // : V -> V'\n    vector<int> index_of; // : V -> int, the index of the vertex in the path that belongs to\n    vector<int> parent; // : V' -> V, one node has -1 as the parent\n    heavy_light_decomposition(int root, vector<vector<int> > const & g) {\n        int n = g.size();\n        vector<int> tour_parent(n, -1);\n        vector<int> euler_tour(n); {\n            int i = 0;\n            stack<int> stk;\n            tour_parent[root] = -1;\n            euler_tour[i ++] = root;\n            stk.push(root);\n            while (not stk.empty()) {\n                int x = stk.top(); stk.pop();\n                for (int y : g[x]) if (y != tour_parent[x]) {\n                    tour_parent[y] = x;\n                    euler_tour[i ++] = y;\n                    stk.push(y);\n                }\n            }\n        }\n        path_of.resize(n);\n        index_of.resize(n);\n        vector<int> subtree_height(n);\n        int path_count = 0;\n        REP_R (i, n) {\n            int y = euler_tour[i];\n            if (y != root) {\n                int x = tour_parent[y];\n                chmax(subtree_height[x], subtree_height[y] + 1);\n            }\n            if (subtree_height[y] == 0) {\n                // make a new path\n                path_of[y] = path_count ++;\n                index_of[y] = 0;\n                path.emplace_back();\n                path.back().push_back(y);\n                parent.push_back(tour_parent[y]);\n            } else {\n                // add to an existing path\n                int i = -1;\n                for (int z : g[y]) {\n                    if (subtree_height[z] == subtree_height[y] - 1) {\n                        i = path_of[z];\n                        break;\n                    }\n                }\n                assert (i != -1);\n                path_of[y] = i;\n                index_of[y] = path[i].size();\n                path[i].push_back(y);\n                parent[i] = tour_parent[y];\n            }\n        }\n    }\n\n    /**\n     * @brief reduce a path-query to range-queries aboud nodes\n     * @arg lca is for the original tree, not the decomposed tree\n     * @arg func is a callback function f(i, l, r), where i in V is an index of path, [l, r) is a range on the path\n     */\n    template <class LowestCommonAncestor, class Func>\n    void path_node_do_something(LowestCommonAncestor const & lca, int x, int y, Func func) const {\n        int z = lca(x, y);\n        auto climb = [&](int & x) {\n            while (path_of[x] != path_of[z]) {\n                int i = path_of[x];\n                func(i, index_of[x], path[i].size());\n                x = parent[i];\n            }\n        };\n        climb(x);\n        climb(y);\n        int i = path_of[z];\n        if (index_of[x] > index_of[y]) swap(x, y);\n        func(i, index_of[x], index_of[y] + 1);\n    }\n};\n\n/**\n * @brief sparse table on a monoid\n * @note space: O(N log N)\n * @note time:  O(N log N) for construction; O(1) for query\n */\ntemplate <class Monoid>\nstruct sparse_table {\n    typedef typename Monoid::underlying_type underlying_type;\n    vector<vector<underlying_type> > table;\n    Monoid mon;\n    sparse_table() = default;\n    sparse_table(vector<underlying_type> const & data, Monoid const & a_mon = Monoid())\n            : mon(a_mon) {\n        int n = data.size();\n        int log_n = 32 - __builtin_clz(n);\n        table.resize(log_n, vector<underlying_type>(n, mon.unit()));\n        table[0] = data;\n        for (int k = 0; k < log_n-1; ++ k) {\n            for (int i = 0; i < n; ++ i) {\n                table[k+1][i] = mon.append(table[k][i], i + (1ll<<k) < n ? table[k][i + (1ll<<k)] : mon.unit());\n            }\n        }\n    }\n    underlying_type range_concat(int l, int r) const {\n        assert (0 <= l and l <= r and r <= table[0].size());\n        if (l == r) return mon.unit();\n        int k = 31 - __builtin_clz(r - l);  // log2\n        return mon.append(table[k][l], table[k][r - (1ll<<k)]);\n    }\n};\n\nstruct indexed_min_monoid {\n    typedef pair<int, int> underlying_type;\n    underlying_type unit() const { return { INT_MAX, INT_MAX }; }\n    underlying_type append(underlying_type a, underlying_type b) const { return min(a, b); }\n};\n\nstruct lowest_common_ancestor {\n    sparse_table<indexed_min_monoid> table;\n    vector<int> index;\n    lowest_common_ancestor() = default;\n    /**\n     * @note O(N)\n     * @param g is an adjacent list of a tree\n     */\n    lowest_common_ancestor(int root, vector<vector<int> > const & g) {\n        vector<pair<int, int> > tour;\n        index.assign(g.size(), -1);\n        function<void (int, int, int)> go = [&](int i, int parent, int depth) {\n            index[i] = tour.size();\n            tour.emplace_back(depth, i);\n            for (int j : g[i]) if (j != parent) {\n                go(j, i, depth + 1);\n                tour.emplace_back(depth, i);\n            }\n        };\n        go(root, -1, 0);\n        table = sparse_table<indexed_min_monoid>(tour);\n    }\n    /**\n     * @note O(1)\n     */\n    int operator () (int x, int y) const {\n        assert (0 <= x and x < index.size());\n        assert (0 <= y and y < index.size());\n        x = index[x];\n        y = index[y];\n        if (x > y) swap(x, y);\n        return table.range_concat(x, y + 1).second;\n    }\n};\n\n/**\n * @brief a fully indexable dictionary\n * @note space complexity o(N). 1.5N-bit consumed\n */\nclass fully_indexable_dictionary {\n    static constexpr size_t block_size = 64;\n    vector<uint64_t> block;\n    vector<int32_t> rank_block;  // a blocked cumulative sum\npublic:\n    size_t size;\n    fully_indexable_dictionary() = default;\n    template <typename T>\n    fully_indexable_dictionary(vector<T> const & bits) {\n        size = bits.size();\n        size_t block_count = size / block_size + 1;\n        block.resize(block_count);\n        REP (i, size) if (bits[i]) {\n            block[i / block_size] |= (1ull << (i % block_size));\n        }\n        rank_block.resize(block_count);\n        rank_block[0] = 0;\n        REP (i, block_count - 1) {\n            rank_block[i + 1] = rank_block[i] + __builtin_popcountll(block[i]);\n        }\n    }\n    /**\n     * @brief count the number of value in [0, r)\n     * @note O(1)\n     */\n    int rank(bool value, int r) const {\n        assert (0 <= r and r <= size);\n        uint64_t mask = (1ull << (r % block_size)) - 1;\n        int rank_1 = rank_block[r / block_size] + __builtin_popcountll(block[r /block_size] & mask);\n        return value ? rank_1 : r - rank_1;\n    }\n    int rank(bool value, int l, int r) const {\n        assert (0 <= l and l <= r and r <= size);\n        return rank(value, r) - rank(value, l);\n    }\n};\n\n/**\n * @brief a wavelet matrix\n * @tparam BITS express the range [0, 2^BITS) of values. You can assume BITS \\le \\log N, using coordinate compression\n */\ntemplate <int BITS>\nstruct wavelet_matrix {\n    static_assert (BITS < CHAR_BIT * sizeof(uint64_t), \"\");\n    array<fully_indexable_dictionary, BITS> fid;\n    array<int, BITS> zero_count;\n    wavelet_matrix() = default;\n    /**\n     * @note O(N BITS)\n     */\n    template <typename T>\n    wavelet_matrix(vector<T> data) {\n        int size = data.size();\n        REP (i, size) {\n            assert (0 <= data[i] and data[i] < (1ull << BITS));\n        }\n        // bit-inversed radix sort\n        vector<char> bits(size);\n        vector<T> next(size);\n        REP_R (k, BITS) {\n            auto low  = next.begin();\n            auto high = next.rbegin();\n            REP (i, size) {\n                bits[i] = bool(data[i] & (1ull << k));\n                (bits[i] ? *(high ++) : *(low ++)) = data[i];\n            }\n            fid[k] = fully_indexable_dictionary(bits);\n            zero_count[k] = low - next.begin();\n            reverse(next.rbegin(), high);\n            data.swap(next);\n        }\n    }\n    /**\n     * @brief count the number of values in [value_l, value_r) in range [l, r)\n     * @note O(BITS)\n     */\n    int range_frequency(int l, int r, uint64_t value_l, uint64_t value_r) const {\n        assert (0 <= l and l <= r and r <= fid[0].size);\n        assert (0 <= value_l and value_l <= value_r and value_r <= (1ull << BITS));\n        return range_frequency(BITS - 1, l, r, 0, value_l, value_r);\n    }\n    int range_frequency(int k, int l, int r, uint64_t v, uint64_t a, uint64_t b) const {\n        if (l == r) return 0;\n        if (k == -1) return (a <= v and v < b) ? r - l : 0;\n        uint64_t nv  =  v |  (1ull << k);\n        uint64_t nnv = nv | ((1ull << k) - 1);\n        if (nnv < a or b <= v) return 0;\n        if (a <= v and nnv < b) return r - l;\n        int lc = fid[k].rank(1, l);\n        int rc = fid[k].rank(1, r);\n        return\n            range_frequency(k - 1,             l - lc,             r - rc,  v, a, b) +\n            range_frequency(k - 1, lc + zero_count[k], rc + zero_count[k], nv, a, b);\n    }\n};\n\n/**\n * @brie a flexible binary search\n * @param[in] p  a monotone predicate defined on [l, r)\n * @return  \\min \\{ x \\in [l, r) \\mid p(x) \\}, or r if it doesn't exist\n */\ntemplate <typename UnaryPredicate>\nll binsearch(ll l, ll r, UnaryPredicate p) {\n    assert (l <= r);\n    -- l;\n    while (r - l > 1) {\n        ll m = (l + r) / 2;\n        (p(m) ? r : l) = m;\n    }\n    return r;\n}\n\nint main() {\n    // input\n    int n, queries; scanf(\"%d%d\", &n, &queries);\n    vector<int> x(n); REP (i, n) scanf(\"%d\", &x[i]);\n    vector<vector<int> > g(n);\n    REP (i, n - 1) {\n        int a, b; scanf(\"%d%d\", &a, &b);\n        -- a; -- b;\n        g[a].push_back(b);\n        g[b].push_back(a);\n    }\n    // prepare\n    // // coordinate compression\n    auto uncompress = x;\n    sort(ALL(uncompress));\n    uncompress.erase(unique(ALL(uncompress)), uncompress.end());\n    x = apply_compression(coordinate_compression_map(x), x);\n    // // heavy light decomposition\n    constexpr int root = 0;\n    heavy_light_decomposition hl(root, g);\n    lowest_common_ancestor lca(root, g);\n    // // wavelet matrix\n    assert (n < (1 << 17));\n    vector<wavelet_matrix<17> > wm;\n    for (auto const & path : hl.path) {\n        vector<int> y;\n        for (int i : path) {\n            y.push_back(x[i]);\n        }\n        wm.emplace_back(y);\n    }\n    // serve\n    while (queries --) {\n        int v, w, l; scanf(\"%d%d%d\", &v, &w, &l);\n        -- v; -- w; -- l;\n        // binary search\n        auto pred = [&](int value) {\n            int cnt = 0;\n            hl.path_node_do_something(lca, v, w, [&](int i, int il, int ir) {\n                cnt += wm[i].range_frequency(il, ir, 0, value + 1);\n            });\n            return cnt > l;\n        };\n        int result = uncompress[binsearch(0, n, pred)];\n        printf(\"%d\\n\", result);\n    }\n    return 0;\n}\n```",
        "postTime": 1569648602,
        "uid": 145596,
        "name": "AquaRio",
        "ccfLevel": 6,
        "title": "\u9898\u89e3 AT36 \u3010L\u756a\u76ee\u306e\u6570\u5b57\u3011"
    }
]