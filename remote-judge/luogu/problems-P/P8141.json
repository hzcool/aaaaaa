{
    "description": "Vector embeddings are a common tool in machine learning systems.\nComplex real-world concepts (for instance, words in a dictionary) are mapped onto vectors of real numbers.\nIf embeddings are trained properly, related concepts remain close together in the vector space, so questions like \"are these two words synonyms?\" can be reduced to straightforward mathematical tests.\n\nYou have been hired by Ye Olde Ice Cream Shoppe to create an embedding model for flavors, so that when they are out of an ice cream flavor they can recommend related flavors to customers.\nAfter training your embedding on six cloud datacenters for four months, you finally had the perfect flavor model!\nYou were ready to revolutionize the ice cream industry on your street and, dare we say it, your neighborhood!\nWell, until you accidentally dripped some free ice cream on your keyboard and deleted half the data.\nThe Shoppe cannot afford the 30 billion rubles needed to retrain the model, so you are in trouble.\n\nFortunately, you still have various training results lying around.\nFor a given deleted vector, the training data tells you how close it was to some known flavor vectors.\nThe closeness of vectors $A$ and $B$ is just the standard Euclidean distance metric (that is, the length of the vector $A - B$).\nWrite a tool that reconstructs embeddings which are consistent with the training results.",
    "inputFormat": "The first line contains two integers $d$ and $n$, where $d$ ($1 \\leq d \\leq 500$) is the number of dimensions of the\nvectors, and $n$ ($1 \\leq n \\leq 500$) is the number of training results for a deleted embedding vector you want to reconstruct.\nEach of the next $n$ lines describes a training result using $d + 1$ numbers $x_1, \\dots, x_d$ and $e$.\nIn a training result, $x_1, \\dots, x_d$ ($-100 \\leq x_i \\leq 100$) are the coordinates of a known vector, and \n$e$ ($0 \\leq e \\leq 5\\,000$) is the Euclidean distance from that vector to the deleted one.\n\nYour submission will be tested only with the sample inputs given below and inputs generated according to the following procedure.\nFirst, $d$ and $n$ are chosen.\nThen, $n$ input vectors and $1$ output vector, each with dimension $d$, are chosen at random.\nThe $d \\cdot (n + 1)$ coordinates are independent and uniformly distributed in the interval $[-100,100]$.\nNext, the Euclidean distance from each input vector to the output vector is computed.\nFinally, the output vector is discarded.\nCalculations use double-precision floating-point numbers.\nNumbers obtained using this procedure appear in the input with $17$ digits after the decimal point.",
    "outputFormat": "Output $d$ values, the coordinates of any vector that has the given distance to each training vector with an absolute or relative error of at most $10^{-5}$.",
    "samples": [
        [
            "2 3\n0 0 2.5\n3 0 2.5\n1.5 0.5 2.5",
            "1.5 -2"
        ],
        [
            "2 2\n0 0 2\n4 -4 6",
            "1.414213562373 1.414213562373"
        ],
        [
            "4 3\n0 1 2 3 2\n1 2 -1 7 5\n1 0.3 3.4 1.2 3.3",
            "1 2 3 4"
        ]
    ],
    "hint": "",
    "translation": "**\u3010\u9898\u76ee\u63cf\u8ff0\u3011**\n\n\u5411\u91cf\u5d4c\u5165\u662f\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e2d\u7684\u4e00\u79cd\u5e38\u7528\u5de5\u5177\u3002\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u67d0\u4e9b\u590d\u6742\u7684\u6982\u5ff5\uff08\u4f8b\u5982\u8bcd\u5178\u4e2d\u7684\u5355\u8bcd\uff09\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u6620\u5c04\u5230\u4e00\u4e2a\u5b9e\u5411\u91cf\u4e0a\u3002\u5982\u679c\u80fd\u8ba9\u673a\u5668\u6b63\u786e\u5730\u8bad\u7ec3\u5411\u91cf\u5d4c\u5165\uff0c\u7531\u4e8e\u76f8\u5173\u6982\u5ff5\u5728\u5411\u91cf\u7a7a\u95f4\u4e2d\u4fdd\u6301\u7740\u7d27\u5bc6\u7684\u8054\u7cfb\uff0c\u56e0\u6b64\u50cf\u201c\u8fd9\u4e24\u4e2a\u5355\u8bcd\u662f\u540c\u4e49\u8bcd\u5417\uff1f\u201d\u8fd9\u79cd\u95ee\u9898\u53ef\u4ee5\u7b80\u5316\u4e3a\u7b80\u5355\u7684\u6570\u5b66\u6d4b\u8bd5\u4e86\u3002\n\n\u4f60\u6700\u8fd1\u88ab Ye Olde \u51b0\u6dc7\u6dcb\u4e13\u67dc\u53d7\u96c7\uff0c\u4e13\u95e8\u8d1f\u8d23\u4e3a\u51b0\u6dc7\u6dcb\u53e3\u5473\u521b\u5efa\u4e00\u4e2a\u5411\u91cf\u5d4c\u5165\u5f0f\u6a21\u578b\uff0c\u8fd9\u6837\u5f53\u4e00\u79cd\u53e3\u5473\u7684\u51b0\u6dc7\u6dcb\u5356\u5b8c\u4ee5\u540e\uff0c\u8fd9\u4e2a\u5d4c\u5165\u5f0f\u6a21\u578b\u5c31\u53ef\u4ee5\u50cf\u987e\u5ba2\u63a8\u8350\u5176\u5b83\u5473\u9053\u76f8\u8fd1\u7684\u51b0\u6dc7\u6dcb\u3002\u5728\u516d\u4e2a\u4e91\u6570\u636e\u4e2d\u5fc3\u91cc\u8bad\u7ec3\u4e86\u56db\u4e2a\u6708\u4ee5\u540e\uff0c\u4f60\u7ec8\u4e8e\u62e5\u6709\u4e86\u4e00\u4e2a\u5b8c\u7f8e\u7684\u6a21\u578b\uff0c\u6b63\u51c6\u5907\u597d\u6539\u53d8\u4f60\u6240\u5728\u8857\u533a\u7684\u51b0\u6dc7\u6dcb\u884c\u4e1a\uff0c\u4e43\u81f3\u6574\u4e2a\u8857\u533a\u65f6\uff0c\u4f60\u4e0d\u5c0f\u5fc3\u628a\u4e00\u4e9b\u514d\u8d39\u7684\u51b0\u6dc7\u6dcb\u6ef4\u5230\u4e86\u952e\u76d8\u4e0a\uff0c\u5bfc\u81f4\u4e00\u534a\u7684\u6570\u636e\u88ab\u5220\u9664\u3002\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u9700\u8981\u82b1\u8d39 300 \u4ebf\u5362\u5e03\uff0c\u800c\u4e13\u67dc\u663e\u7136\u627f\u53d7\u4e0d\u4e86\u8fd9\u4e48\u9ad8\u7684\u4ef7\u683c\uff0c\u56e0\u6b64\u4f60\u9677\u5165\u4e86\u5de8\u5927\u7684\u9ebb\u70e6\u4e4b\u4e2d\u3002\u5e78\u8fd0\u7684\u662f\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7\u5269\u4e0b\u7684\u6570\u636e\u6765\u8fd8\u539f\u51fa\u88ab\u5220\u9664\u7684\u5411\u91cf\u3002\u5177\u4f53\u5730\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u7ed9\u5b9a\u7684\u88ab\u5220\u9664\u7684\u5411\u91cf\uff0c\u6570\u636e\u4f1a\u544a\u8bc9\u4f60\u5b83\u4e0e\u67d0\u4e9b\u5df2\u77e5\u7684\u5473\u9053\u5411\u91cf\u7684\u63a5\u8fd1\u7a0b\u5ea6\u3002\u4e24\u4e2a\u5411\u91cf $A,B$ \u7684\u63a5\u8fd1\u7a0b\u5ea6\u5373\u4e3a\u8fd9\u4e24\u4e2a\u5411\u91cf\u4e4b\u95f4\u7684\u6807\u51c6\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\uff08\u5373\u5411\u91cf $A-B$ \u7684\u957f\u5ea6\uff09\u3002\n\n\u73b0\u5728\uff0c\u7ed9\u5b9a\u5411\u91cf\u6240\u5904\u7684\u7a7a\u95f4\u7ef4\u5ea6 $d$ \u548c\u5df2\u77e5\u5411\u91cf\u4e2a\u6570 $n$\uff0c\u5e76\u7ed9\u5b9a\u6240\u6709 $n$ \u4e2a\u5411\u91cf\u7684\u5750\u6807 $(x_{i,1},x_{i,2},\\cdots,x_{i,d})$ \u548c\u5230\u540c\u4e00\u4e2a\u88ab\u5220\u9664\u7684\u5411\u91cf\u7684\u6807\u51c6\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb $e_i$\uff0c\u8bf7\u4f60\u7f16\u5199\u4e00\u4e2a\u7a0b\u5e8f\uff0c\u6c42\u51fa\u88ab\u5220\u9664\u7684\u5411\u91cf\u7684\u5750\u6807\u3002\n\n**\u3010\u8f93\u5165\u683c\u5f0f\u3011**\n\n\u7b2c\u4e00\u884c\u8f93\u5165\u4e24\u4e2a\u6574\u6570 $d,n$\uff0c\u5206\u522b\u8868\u793a\u5411\u91cf\u7a7a\u95f4\u7684\u7ef4\u5ea6\u548c\u5411\u91cf\u4e2a\u6570\u3002  \n\u968f\u540e $n$ \u884c\uff0c\u6bcf\u884c $d+1$ \u4e2a\u6574\u6570 $x_{i,1},x_{i,2},\\cdots,x_{i,d},e_i$\uff0c\u5176\u4e2d\u524d $d$ \u4e2a\u6574\u6570\u63cf\u8ff0\u4e86\u7b2c $i$ \u4e2a\u5411\u91cf\u7684\u5750\u6807\uff0c\u7b2c $d+1$ \u4e2a\u6574\u6570\u5219\u8868\u793a\u7b2c $i$ \u4e2a\u5411\u91cf\u4e0e\u88ab\u5220\u9664\u7684\u5411\u91cf\u4e4b\u95f4\u7684\u6807\u51c6\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u3002\n\n\u4f60\u63d0\u4ea4\u7684\u4ee3\u7801\u53ea\u4f1a\u5728\u6837\u4f8b\u8f93\u5165\u6570\u636e\u548c\u6309\u4ee5\u4e0b\u65b9\u5f0f\u751f\u6210\u7684\u8f93\u5165\u6570\u636e\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff1a\n\n- \u5728\u533a\u95f4 $[1,500]$ \u4e2d\u9009\u51fa\u4e24\u4e2a\u6574\u6570\u4f5c\u4e3a $d,n$\u3002\n- \u968f\u673a\u751f\u6210 $n$ \u4e2a $d$ \u7ef4\u8f93\u5165\u5411\u91cf\u548c\u4e00\u4e2a $d$ \u7ef4\u8f93\u51fa\u5411\u91cf\u3002\u8fd9 $d\\cdot(n+1)$ \u4e2a\u5750\u6807\u5728\u533a\u95f4 $[-100,100]$ \u4e2d\u72ec\u7acb\u4e14\u5747\u5300\u5730\u751f\u6210\u3002\n- \u5bf9\u4e8e\u6bcf\u4e2a\u8f93\u5165\u5411\u91cf\uff0c\u8ba1\u7b97\u5176\u4e0e\u8f93\u51fa\u5411\u91cf\u4e4b\u95f4\u7684\u6807\u51c6\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u3002\n- \u5ffd\u7565\u8f93\u51fa\u5411\u91cf\u3002\n\n\u6240\u6709\u5728\u4e0a\u8ff0\u8fc7\u7a0b\u4e2d\u7684\u8ba1\u7b97\u4f7f\u7528\u53cc\u7cbe\u5ea6\u6d6e\u70b9\u6570\uff0c\u7528\u8fd9\u79cd\u65b9\u5f0f\u751f\u6210\u7684\u6240\u6709\u5b9e\u6570\u5747\u4fdd\u7559\u5230\u5c0f\u6570\u70b9\u540e $17$ \u4f4d\u3002\n\n**\u3010\u8f93\u51fa\u683c\u5f0f\u3011**\n\n\u8f93\u51fa $d$ \u4e2a\u6574\u6570\uff0c\u63cf\u8ff0\u88ab\u5220\u9664\u5411\u91cf\u7684\u5750\u6807\u3002\u4f60\u9700\u8981\u4fdd\u8bc1\u4f60\u8f93\u51fa\u7684\u7b54\u6848\u548c\u6807\u51c6\u7b54\u6848\u4e4b\u95f4\u7684\u8bef\u5dee\u4e0d\u4f1a\u8d85\u8fc7 $10^{-5}$\u3002\n\n**\u3010\u6837\u4f8b\u3011**\n\n\u89c1\u300e\u8f93\u5165\u8f93\u51fa\u6837\u4f8b\u300f\u90e8\u5206\u3002\n\n**\u3010\u6570\u636e\u8303\u56f4\u3011**\n\n\u5bf9\u4e8e\u6240\u6709\u6570\u636e\uff1a\n\n- $1\\leqslant d,n\\leqslant 500$\u3002\n- $-100\\leqslant x_{i,j}\\leqslant 100$\u3002\n- $0\\leqslant e_i\\leqslant 5000$\u3002\n\nTranslated by Eason_AC"
}